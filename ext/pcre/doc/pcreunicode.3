.TH PCREUNICODE 3
.SH NAME
PCRE - Perl-compatible regular expressions
.SH "UTF-8 AND UNICODE PROPERTY SUPPORT"
.rs
.sp
In order process UTF-8 strings, you must build PCRE to include UTF-8 support in
the code, and, in addition, you must call
.\" HREF
\fBpcre_compile()\fP
.\"
with the PCRE_UTF8 option flag, or the pattern must start with the sequence
(*UTF8). When either of these is the case, both the pattern and any subject
strings that are matched against it are treated as UTF-8 strings instead of
strings of 1-byte characters. PCRE does not support any other formats (in
particular, it does not support UTF-16).
.P
If you compile PCRE with UTF-8 support, but do not use it at run time, the
library will be a bit bigger, but the additional run time overhead is limited
to testing the PCRE_UTF8 flag occasionally, so should not be very big.
.P
If PCRE is built with Unicode character property support (which implies UTF-8
support), the escape sequences \ep{..}, \eP{..}, and \eX are supported.
The available properties that can be tested are limited to the general
category properties such as Lu for an upper case letter or Nd for a decimal
number, the Unicode script names such as Arabic or Han, and the derived
properties Any and L&. A full list is given in the
.\" HREF
\fBpcrepattern\fP
.\"
documentation. Only the short names for properties are supported. For example,
\ep{L} matches a letter. Its Perl synonym, \ep{Letter}, is not supported.
Furthermore, in Perl, many properties may optionally be prefixed by "Is", for
compatibility with Perl 5.6. PCRE does not support this.
.
.
.\" HTML <a name="utf8strings"></a>
.SS "Validity of UTF-8 strings"
.rs
.sp
When you set the PCRE_UTF8 flag, the strings passed as patterns and subjects
are (by default) checked for validity on entry to the relevant functions. From
release 7.3 of PCRE, the check is according the rules of RFC 3629, which are
themselves derived from the Unicode specification. Earlier releases of PCRE
followed the rules of RFC 2279, which allows the full range of 31-bit values (0
to 0x7FFFFFFF). The current check allows only values in the range U+0 to
U+10FFFF, excluding U+D800 to U+DFFF.
.P
The excluded code points are the "Low Surrogate Area" of Unicode, of which the
Unicode Standard says this: "The Low Surrogate Area does not contain any
character assignments, consequently no character code charts or namelists are
provided for this area. Surrogates are reserved for use with UTF-16 and then
must be used in pairs." The code points that are encoded by UTF-16 pairs are
available as independent code points in the UTF-8 encoding. (In other words,
the whole surrogate thing is a fudge for UTF-16 which unfortunately messes up
UTF-8.)
.P
If an invalid UTF-8 string is passed to PCRE, an error return is given. At
compile time, the only additional information is the offset to the first byte
of the failing character. The runtime functions \fBpcre_exec()\fP and
\fBpcre_dfa_exec()\fP also pass back this information, as well as a more
detailed reason code if the caller has provided memory in which to do this.
.P
In some situations, you may already know that your strings are valid, and
therefore want to skip these checks in order to improve performance. If you set
the PCRE_NO_UTF8_CHECK flag at compile time or at run time, PCRE assumes that
the pattern or subject it is given (respectively) contains only valid UTF-8
codes. In this case, it does not diagnose an invalid UTF-8 string.
.P
If you pass an invalid UTF-8 string when PCRE_NO_UTF8_CHECK is set, what
happens depends on why the string is invalid. If the string conforms to the
"old" definition of UTF-8 (RFC 2279), it is processed as a string of characters
in the range 0 to 0x7FFFFFFF by \fBpcre_dfa_exec()\fP and the interpreted
version of \fBpcre_exec()\fP. In other words, apart from the initial validity
test, these functions (when in UTF-8 mode) handle strings according to the more
liberal rules of RFC 2279. However, the just-in-time (JIT) optimization for
\fBpcre_exec()\fP supports only RFC 3629. If you are using JIT optimization, or
if the string does not even conform to RFC 2279, the result is undefined. Your
program may crash.
.P
If you want to process strings of values in the full range 0 to 0x7FFFFFFF,
encoded in a UTF-8-like manner as per the old RFC, you can set
PCRE_NO_UTF8_CHECK to bypass the more restrictive test. However, in this
situation, you will have to apply your own validity check, and avoid the use of
JIT optimization.
.
.
.SS "General comments about UTF-8 mode"
.rs
.sp
1. An unbraced hexadecimal escape sequence (such as \exb3) matches a two-byte
UTF-8 character if the value is greater than 127.
.P
2. Octal numbers up to \e777 are recognized, and match two-byte UTF-8
characters for values greater than \e177.
.P
3. Repeat quantifiers apply to complete UTF-8 characters, not to individual
bytes, for example: \ex{100}{3}.
.P
4. The dot metacharacter matches one UTF-8 character instead of a single byte.
.P
5. The escape sequence \eC can be used to match a single byte in UTF-8 mode,
but its use can lead to some strange effects because it breaks up multibyte
characters (see the description of \eC in the
.\" HREF
\fBpcrepattern\fP
.\"
documentation). The use of \eC is not supported in the alternative matching
function \fBpcre_dfa_exec()\fP, nor is it supported in UTF-8 mode by the JIT
optimization of \fBpcre_exec()\fP. If JIT optimization is requested for a UTF-8
pattern that contains \eC, it will not succeed, and so the matching will be
carried out by the normal interpretive function.
.P
6. The character escapes \eb, \eB, \ed, \eD, \es, \eS, \ew, and \eW correctly
test characters of any code value, but, by default, the characters that PCRE
recognizes as digits, spaces, or word characters remain the same set as before,
all with values less than 256. This remains true even when PCRE is built to
include Unicode property support, because to do otherwise would slow down PCRE
in many common cases. Note in particular that this applies to \eb and \eB,
because they are defined in terms of \ew and \eW. If you really want to test
for a wider sense of, say, "digit", you can use explicit Unicode property tests
such as \ep{Nd}. Alternatively, if you set the PCRE_UCP option, the way that
the character escapes work is changed so that Unicode properties are used to
determine which characters match. There are more details in the section on
.\" HTML <a href="pcrepattern.html#genericchartypes">
.\" </a>
generic character types
.\"
in the
.\" HREF
\fBpcrepattern\fP
.\"
documentation.
.P
7. Similarly, characters that match the POSIX named character classes are all
low-valued characters, unless the PCRE_UCP option is set.
.P
8. However, the horizontal and vertical whitespace matching escapes (\eh, \eH,
\ev, and \eV) do match all the appropriate Unicode characters, whether or not
PCRE_UCP is set.
.P
9. Case-insensitive matching applies only to characters whose values are less
than 128, unless PCRE is built with Unicode property support. Even when Unicode
property support is available, PCRE still uses its own character tables when
checking the case of low-valued characters, so as not to degrade performance.
The Unicode property information is used only for characters with higher
values. Furthermore, PCRE supports case-insensitive matching only when there is
a one-to-one mapping between a letter's cases. There are a small number of
many-to-one mappings in Unicode; these are not supported by PCRE.
.
.
.SH AUTHOR
.rs
.sp
.nf
Philip Hazel
University Computing Service
Cambridge CB2 3QH, England.
.fi
.
.
.SH REVISION
.rs
.sp
.nf
Last updated: 19 October 2011
Copyright (c) 1997-2011 University of Cambridge.
.fi
